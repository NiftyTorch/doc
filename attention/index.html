<!DOCTYPE html>
<!--[if IE 8]><html class="no-js lt-ie9" lang="en" > <![endif]-->
<!--[if gt IE 8]><!--> <html class="no-js" lang="en" > <!--<![endif]-->
<head>
  <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  
  
  
  <link rel="shortcut icon" href="../img/favicon.ico">
  <title>Attention - NiftyTorch Documentation</title>
  <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Lato:400,700|Roboto+Slab:400,700|Inconsolata:400,700" />

  <link rel="stylesheet" href="../css/theme.css" />
  <link rel="stylesheet" href="../css/theme_extra.css" />
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.12.0/styles/github.min.css" />
  
  <script>
    // Current page data
    var mkdocs_page_name = "Attention";
    var mkdocs_page_input_path = "attention.md";
    var mkdocs_page_url = null;
  </script>
  
  <script src="../js/jquery-2.1.1.min.js" defer></script>
  <script src="../js/modernizr-2.8.3.min.js" defer></script>
  <script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.12.0/highlight.min.js"></script>
  <script>hljs.initHighlightingOnLoad();</script> 
  
</head>

<body class="wy-body-for-nav" role="document">

  <div class="wy-grid-for-nav">

    
    <nav data-toggle="wy-nav-shift" class="wy-nav-side stickynav">
    <div class="wy-side-scroll">
      <div class="wy-side-nav-search">
        <a href=".." class="icon icon-home"> NiftyTorch Documentation</a>
        <div role="search">
  <form id ="rtd-search-form" class="wy-form" action="../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" title="Type search term here" />
  </form>
</div>
      </div>

      <div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="main navigation">
                <ul>
                    <li class="toctree-l1"><a class="reference internal" href="..">NiftyTorch</a>
                    </li>
                </ul>
                <ul class="current">
                    <li class="toctree-l1 current"><a class="reference internal current" href="./">Attention</a>
    <ul class="current">
    <li class="toctree-l2"><a class="reference internal" href="#modules">Modules</a>
        <ul>
    <li class="toctree-l3"><a class="reference internal" href="#positional-attention">Positional Attention</a>
    </li>
    <li class="toctree-l3"><a class="reference internal" href="#channel-attention">Channel Attention</a>
    </li>
        </ul>
    </li>
    </ul>
                    </li>
                </ul>
                <ul>
                    <li class="toctree-l1"><a class="reference internal" href="../layers/">Layers</a>
                    </li>
                </ul>
                <ul>
                    <li class="toctree-l1"><a class="reference internal" href="../loader/">Loader</a>
                    </li>
                </ul>
                <ul>
                    <li class="toctree-l1"><a class="reference internal" href="../loss/">Loss</a>
                    </li>
                </ul>
                <ul>
                    <li class="toctree-l1"><a class="reference internal" href="../models/">Models</a>
                    </li>
                </ul>
                <ul>
                    <li class="toctree-l1"><a class="reference internal" href="../training/">Training</a>
                    </li>
                </ul>
                <ul>
                    <li class="toctree-l1"><a class="reference internal" href="../transformations/">Transformations</a>
                    </li>
                </ul>
                <ul>
                    <li class="toctree-l1"><a class="reference internal" href="../license/">Licence</a>
                    </li>
                </ul>
      </div>
    </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap">

      
      <nav class="wy-nav-top" role="navigation" aria-label="top navigation">
        <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
        <a href="..">NiftyTorch Documentation</a>
      </nav>

      
      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="breadcrumbs navigation">
  <ul class="wy-breadcrumbs">
    <li><a href="..">Docs</a> &raquo;</li>
    
      
    
    <li>Attention</li>
    <li class="wy-breadcrumbs-aside">
      
    </li>
  </ul>
  
  <hr/>
</div>
          <div role="main">
            <div class="section">
              
                <h1 id="attention">Attention</h1>
<p>The Attention can be used in the form of self-attention to identify important positional features or channel features. It can be also used <strong>to add demographic data</strong> into the model.</br></p>
<h2 id="modules">Modules</h2>
<h3 id="positional-attention">Positional Attention</h3>
<p>The code below demonstrates how to use the Positional Attention Module (PAM).<br></p>
<p>The object constructer for the Position Attention Module used to attend to different location specific features via aggreagation context.<br></p>
<p>Parameters for Constructor:<br></p>
<ul>
<li> in_shape (int,required): the number of channels in the input tensor for PAM Module<br>
<li> reduction (int,default = 8): the compression in features channels to be done before computing the attention<br>
<li> query_conv_kernel (int, default = 1): The kernel size for convolutional filter applied in query features<br>
<li> key_conv_kernel (int, default = 1): The kernel size for convolutional filter applied in key features<br>
<li> value_conv_kernel (int, default = 1): The kernel size for convolutional filter applied in value features<br>
</ul>

<p>Usage:</p>
<pre><code class="python">from niftytorch.attention.attention import pam
PAM = pam(in_shape = 512,reduction = 8,query_conv_kernel = 3,key_conv_kernel = 3,value_conv_kernel = 3)
t = torch.rand(64,512,32,32)
out,attention = PAM(t)
print(out.shape)
&gt;&gt;&gt; 64 x 512 x 32 x 32
print(attention.shape)
&gt;&gt;&gt; 64 x 1024 x 1024
</code></pre>

<p>The PAM returns two tensors where the first tensor is the output from positional attention and the second is the attention map.<br></p>
<h3 id="channel-attention">Channel Attention</h3>
<p>The code below demonstrates how to use the Channel Attention Module (CAM).<br></p>
<p>The object constructer for the Channel Attention Module used to attend to different channel specific features.<br></p>
<p>Parameters for Constructor:<br></p>
<ul>
<li> in_shape (int,required): the number of channels in the input tensor for CAM Module<br>
</ul>

<p>Usage:</p>
<pre><code class="python">from niftytorch.attention.attention import cam
PAM = cam(512)
t = torch.rand(64,512,32,32)
out,attention = CAM(t)
print(out.shape)
&gt;&gt;&gt; 64 x 512 x 32 x 32
print(attention.shape)
&gt;&gt;&gt; 64 x 512 x 512
</code></pre>

<p>The CAM returns two tensors where the first tensor is the output from channel-wise attention and the second is the attention map.<br></p>
              
            </div>
          </div>
          <footer>
  
    <div class="rst-footer-buttons" role="navigation" aria-label="footer navigation">
      
        <a href="../layers/" class="btn btn-neutral float-right" title="Layers">Next <span class="icon icon-circle-arrow-right"></span></a>
      
      
        <a href=".." class="btn btn-neutral" title="NiftyTorch"><span class="icon icon-circle-arrow-left"></span> Previous</a>
      
    </div>
  

  <hr/>

  <div role="contentinfo">
    <!-- Copyright etc -->
    
  </div>

  Built with <a href="https://www.mkdocs.org/">MkDocs</a> using a <a href="https://github.com/snide/sphinx_rtd_theme">theme</a> provided by <a href="https://readthedocs.org">Read the Docs</a>.
</footer>
      
        </div>
      </div>

    </section>

  </div>

  <div class="rst-versions" role="note" aria-label="versions">
    <span class="rst-current-version" data-toggle="rst-current-version">
      
      
        <span><a href=".." style="color: #fcfcfc;">&laquo; Previous</a></span>
      
      
        <span style="margin-left: 15px"><a href="../layers/" style="color: #fcfcfc">Next &raquo;</a></span>
      
    </span>
</div>
    <script>var base_url = '..';</script>
    <script src="../js/theme.js" defer></script>
      <script src="../search/main.js" defer></script>
    <script defer>
        window.onload = function () {
            SphinxRtdTheme.Navigation.enable(true);
        };
    </script>

</body>
</html>
